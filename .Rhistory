devtools::build_readme()
pkgdown::build_site()
#usethis::use_pkgdown()
devtools::check()
devtools::load_all()
devtools::document()
devtools::build_readme()
pkgdown::build_site()
library(PowerAfterChange)
?find_n_after
library(glmmTMB)
library(tidyverse)
library(DHARMa)
library(emmeans)
library(future)
library(furrr)
library(mvtnorm)
theme_set(theme_bw())
setwd("C:/Users/ebabcock/Box/My Box Notes (Nathan LaSpina)/Simulation based power analysis")
segments <- read.csv("Epi_allfish - by segment.csv")
seg1 <- segments %>% subset(segment == "seg1")
# Ensure fSeason is an unordered factor
seg1$fSite <- as.factor(seg1$fSite)
seg1$fSeason <- as.factor(seg1$Season)
#' Baseline data:
baseline <- subset(seg1, CYR %in% c(2008:2017))
length(unique(baseline$WYR))
data <- read.csv("Epifauna - Zero_counts_&_Env._data.csv")
setwd("~/GitHub/PowerAfterChange")
write.csv(baseline2,"baseline2.csv")
baseline2 <- baseline[complete.cases(baseline[, c("sal", "wd", "sg")]), ]
baseline2 <- baseline %>%
filter(!is.na(sal) & !is.na(wd) & !is.na(sg))
library(glmmTMB)
library(tidyverse)
library(DHARMa)
library(emmeans)
library(future)
library(furrr)
library(mvtnorm)
theme_set(theme_bw())
segments <- read.csv("Epi_allfish - by segment.csv")
seg1 <- segments %>% subset(segment == "seg1")
#' Baseline data:
baseline <- subset(seg1, CYR %in% c(2008:2017))
length(unique(baseline$WYR))
write.csv(baseline,"baseline.csv")
baseline<-read.csv("baseline.csv")
summary(baseline)
sumarize_baseline <- function(baseline,siteVar="site",responseVar="y"){
baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean)),
baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean),
n_sites = n(),
nB=if_else(length(unique(n)===1),unique(n),else NA)
table(baseline$Season)
baseline<-read.csv("baseline.csv")%>%
filter(Season=="DRY")
summary(baseline)
with(baseline,table(year,site))
names(baseline)
summary(baseline)
with(baseline,table(year,site))
names(baseline)
with(baseline,table(CYR,fSite))
sumarize_baseline <- function(baseline,siteVar="site",responseVar="y"){
baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean),
n_sites = n(),
nB=if_else(length(unique(n)===1),unique(n),else NA)
sumarize_baseline <- function(baseline,siteVar="site",responseVar="y"){
baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean),
n_sites = n(),
nB=if_else(length(unique(n)===1),unique(n),NA)
baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean),
n_sites = n(),
nB=if_else(length(unique(n)==1),unique(n),NA)
)
sumarize_baseline <- function(baseline,siteVar="site",responseVar="y"){
baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean),
n_sites = n(),
nB=if_else(length(unique(n)==1),unique(n),NA)
)
if(is_na(nB)){
warning("Number of before samples per site is not consistent across sites. nB is set to NA.")
}
}
sumarize_baseline <- function(baseline,siteVar="site",responseVar="y"){
returnVal<-baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean),
n_sites = n(),
nB=if_else(length(unique(n)==1),unique(n),NA)
)
if(is_na(nB)){
warning("Number of before samples per site is not consistent across sites. nB is set to NA.")
}
return(returnVal)
}
names(baseline)
baseline_summary <- sumarize_baseline(baseline,
siteVar="fSite",
responseVar="total_fish")
siteVar="fSite"
responseVar="total_fish"
baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
)
baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
)
siteVar="fSite"
responseVar="total_fish"
responseVar="total_fish"
baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
)
baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean),
n_sites = n(),
nB=if_else(length(unique(n)==1),unique(n),NA)
)
returnVal<-baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean),
n_sites = n(),
nB=if_else(length(unique(n))==1,unique(n),NA)
)
returnVal<-baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean),
n_sites = n(),
nB=if_else(length(unique(n))==1,unique(n),NA)
)
returnVal<-baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean),
n_sites = n()#,
#    nB=if_else(length(unique(n))==1,unique(n),NA)
)
baseline_summary <- sumarize_baseline(baseline,
siteVar="fSite",
responseVar="total_fish")
baseline<-read.csv("baseline.csv")%>%
filter(Season=="DRY")
summary(baseline)
with(baseline,table(CYR,fSite))
sumarize_baseline <- function(baseline,siteVar="site",responseVar="y"){
returnVal<-baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean),
n_sites = n()#,
nB=if_else(length(unique(n))==1,unique(n),NA)
)
if(any(is.na(returnVal$nB))){
warning("Number of before samples per site is not consistent across sites. nB is set to NA.")
}
return(returnVal)
baseline_summary <- sumarize_baseline(baseline,
siteVar="fSite",
responseVar="total_fish")
sumarize_baseline <- function(baseline,siteVar="site",responseVar="y"){
returnVal<-baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean),
n_sites = n()#,
#            nB=if_else(length(unique(n))==1,unique(n),NA)
)
if(any(is.na(returnVal$nB))){
warning("Number of before samples per site is not consistent across sites. nB is set to NA.")
}
return(returnVal)
}
baseline_summary <- sumarize_baseline(baseline,
siteVar="fSite",
responseVar="total_fish")
sumarize_baseline <- function(baseline,siteVar="site",responseVar="y"){
returnVal<-baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean),
n_sites = n(),
nB=if_else(length(unique(n))==1,unique(n)[1],NA)
)
if(any(is.na(returnVal$nB))){
warning("Number of before samples per site is not consistent across sites. nB is set to NA.")
}
return(returnVal)
}
baseline_summary <- sumarize_baseline(baseline,
siteVar="fSite",
responseVar="total_fish")
baselineSum<-baseline%>%
group_by(fSite,CYR)%>%
summarize(n=n())
baselineSum
summary(baselineSum$n)
baseline<-read.csv("baseline.csv")%>%
filter(Season=="DRY")%>%
group_by(fSite)%>%
mutate(nyears=length(unique(CYR))) %>%
filter(nyears==max(nyears))%>%
ungroup()
baseline<-read.csv("baseline.csv")%>%
filter(Season=="DRY")%>%
group_by(fSite)%>%
mutate(nyears=length(unique(CYR))) %>%
filter(nyears==max(nyears))%>%
ungroup()
with(baseline,table(fsite,CYR))
with(baseline,table(fSite,CYR))
head(baseline)
view(baseline)
table(baseline$nyears)
?filter
baseline<-read.csv("baseline.csv")%>%
filter(Season=="DRY")%>%
group_by(fSite)%>%
mutate(nyears=length(unique(CYR))) %>%
ungroup()%>%
filter(nyears==max(nyears))
with(baseline,table(fSite,CYR))
# Code to process real baseline data
baseline<-read.csv("baseline.csv")%>%
filter(Season=="DRY")%>%
group_by(fSite)%>%
mutate(nyears=length(unique(CYR))) %>%
ungroup()%>%
filter(nyears==max(nyears))
with(baseline,table(fSite,CYR))
sumarize_baseline <- function(baseline,siteVar="site",responseVar="y"){
returnVal<-baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean),
n_sites = n(),
nB=if_else(length(unique(n))==1,unique(n)[1],NA)
)
if(any(is.na(returnVal$nB))){
warning("Number of before samples per site is not consistent across sites. nB is set to NA.")
}
return(returnVal)
}
baseline_summary <- sumarize_baseline(baseline,
siteVar="fSite",
responseVar="total_fish")
baseline_summary
baseline_summary
sumarize_baseline <- function(baseline,siteVar="site",responseVar="y"){
returnVal<-baseline %>%
group_by(!!sym(siteVar)) %>%
summarize(
site_mean = mean(!!sym(responseVar)),
site_sd = sd(!!sym(responseVar)),
n = n()
) %>%
ungroup() %>%
summarize(sd_within = mean(site_sd),
sd_between = sd(site_mean),
n_sites = n(),
nB=if_else(length(unique(n))==1,unique(n)[1],NA)
)
if(any(is.na(returnVal$nB))){
warning("Number of before samples per site is not consistent across sites. nB is set to NA.")
}
return(returnVal)
}
?uniroot
setwd("C:/Users/ebabcock/Dropbox/Babcock Bayesian/homework/HW3")
library(tidyverse)
library(rethinking)
theme_set(theme_bw())
set.seed(9)
breakfast<-data.frame(Z=rbern(50,0.5)) %>%
mutate(breakfast=rbern(50,(1-Z)*0.2+Z*0.8),
weightLoss=rnorm(50,5*Z,0.2))
with(breakfast,round(cor(weightLoss,breakfast),2))
with(breakfast,round(cor(weightLoss[Z==1],breakfast[Z==1]),2))
with(breakfast,round(cor(weightLoss[Z==0],breakfast[Z==0]),2))
ggplot(breakfast,aes(x=breakfast,y=weightLoss,color=factor(Z)))+
geom_point(position = position_jitter(width=0.1))
noControl<-quap(flist=alist(weightloss~dnorm(mu,sigma),
mu<-a+b*breakfast,
a~dnorm(0,1),
b~dnorm(0,1),
sigma~dexp(1)),
data=list(breakfast=breakfast$breakfast,
weightloss=breakfast$weightLoss))
plot(precis(noControl))
precis(noControl)
withControl<-quap(flist=alist(weightloss~dnorm(mu,sigma),
mu<-a+b*breakfast+bz*Z,
a~dnorm(0,1),
b~dnorm(0,1),
bz~dnorm(0,1),
sigma~dexp(1)),
data=list(breakfast=breakfast$breakfast,
weightloss=breakfast$weightLoss,
Z=breakfast$Z))
plot(precis(withControl))
precis(withControl)
posteriors<-extract.samples(withControl)
names(posteriors)
nsim<-length(posteriors$a)
newZ<-sample(breakfast$Z,size=nsim,replace=TRUE) #sample Z
DM0<-with(posteriors,rnorm(nsim,a+b*0+bz*newZ,sigma)) #calculate posterior predicted weighloss with no breakfast
DM1<-with(posteriors,rnorm(nsim,a+b*1+bz*newZ,sigma)) #calculate posterior predicted weighloss with  breakfast
Mcontrast01<-DM1-DM0
ggplot(data.frame(contrast=Mcontrast01),aes(contrast))+
geom_density()
reeffish<-read_csv("case_study1_dataset.csv") %>%
mutate(fished=if_else(ZONE=="FISHED",1,0))%>%
select(rugosity,depth,fished,log.Piscivore.biomass)
summary(reeffish)
round(cor(reeffish),2)
quap1<-quap(flist=alist(lpiscivore~dnorm(mu,sigma),
mu<-a+b1*rugosity,
c(a,b1)~dnorm(0,1),
sigma~dexp(1)),
data=list(lpiscivore=standardize(reeffish$log.Piscivore.biomass),
rugosity=standardize(reeffish$rugosity)))
nlines=100
priorvals<-extract.prior(quap1,n=nlines)
mu<-link(quap1,
post=priorvals,
data=list(rugosity=c(-2,2)),
n=100)
dim(mu)
head(mu)
priorLines<-data.frame(x=rep(-2,nlines),
xend=rep(2,nlines),
y=mu[,1],
yend=mu[,2])
head(priorLines)
ggplot(priorLines)+
geom_segment(aes(x=x,y=y,xend=xend,yend=yend))+
ggtitle("prior")
#Or
priorDF<-data.frame(extract.prior(quap1,n=nlines))
head(priorDF)
ggplot(priorDF)+
geom_abline(aes(intercept=a,slope=b1))+
xlim(-2,2)+
ylim(-10,10)
quap2<-quap(flist=alist(lpiscivore~dnorm(mu,sigma),
mu<-a+b1*rugosity+b2*depth,
c(a,b1,b2)~dnorm(0,1),
sigma~dexp(1)),
data=list(lpiscivore=standardize(reeffish$log.Piscivore.biomass),
depth=standardize(reeffish$depth),
rugosity=standardize(reeffish$rugosity)))
quap3<-quap(flist=alist(lpiscivore~dnorm(mu,sigma),
mu<-a+b1*rugosity+b2*depth+b3*fished,
c(a,b1,b2,b3)~dnorm(0,1),
sigma~dexp(1)),
data=list(lpiscivore=standardize(reeffish$log.Piscivore.biomass),
depth=standardize(reeffish$depth),
rugosity=standardize(reeffish$rugosity),
fished=reeffish$fished),
start=list(a=0,b1=0,b2=0,b3=0,sigma=1))
precis(quap1)
precis(quap2)
precis(quap3)
resTable<-data.frame(model=1:3,
DIC=c(DIC(quap1),DIC(quap2),DIC(quap3)),
WAIC=c(WAIC(quap1)$WAIC,WAIC(quap2)$WAIC,WAIC(quap3)$WAIC),
LOOIC=c(LOO(quap1)$PSIS,LOO(quap2)$PSIS,LOO(quap3)$PSIS)) %>%
mutate(deltaDIC=DIC-min(DIC),
deltaWAIC=WAIC-min(WAIC),
deltaLOOIC=LOOIC-min(LOOIC))
round(resTable,2)
nsim=2
simVals<-data.frame(sim(quap2,n=nsim)) %>%
pivot_longer(cols=everything(),values_to="Simulated") %>%
mutate(Data=rep(standardize(reeffish$log.Piscivore.biomass),nsim),
index=rep(1:nrow(reeffish),nsim))
ggplot(simVals,aes(x=Data,y=Simulated))+
geom_point(color="blue",alpha=0.5)+
geom_abline()
#or
ggplot(simVals,aes(x=index,y=Simulated))+
geom_point(color="blue",alpha=0.5)+
geom_point(aes(x=index,y=Data),size=3)
#or
simVals<-sim(quap2,n=10)
bayesplot::ppc_scatter(y=as.vector(standardize(reeffish$log.Piscivore.biomass)),yrep=simVals)
